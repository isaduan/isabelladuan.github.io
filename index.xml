<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Isabella Duan</title><link>https://github.com/isaduan/isabelladuan.github.io.git/</link><description>Recent content on Isabella Duan</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 03 Dec 2022 17:08:10 +0000</lastBuildDate><atom:link href="https://github.com/isaduan/isabelladuan.github.io.git/index.xml" rel="self" type="application/rss+xml"/><item><title>Race to the Top: Rethink Benchmark-Making for Safe AI Development</title><link>https://github.com/isaduan/isabelladuan.github.io.git/posts/first/</link><pubDate>Sat, 03 Dec 2022 17:08:10 +0000</pubDate><guid>https://github.com/isaduan/isabelladuan.github.io.git/posts/first/</guid><description>Executive Summary Benchmarks support the empirical, quantitative evaluation of progress in AI research. Although benchmarks are ubiquitous in most subfields of machine learning, they are still rare in the subfield of AI safety.
In this post, I argue that creating benchmarks should be a high priority for AI safety. While this idea is not new, I think it may still be underrated. Among other benefits, benchmarks would make it much easier to:</description></item><item><title>Archives</title><link>https://github.com/isaduan/isabelladuan.github.io.git/archives/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://github.com/isaduan/isabelladuan.github.io.git/archives/</guid><description>archieves</description></item></channel></rss>