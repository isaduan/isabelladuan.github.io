<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Isabella Duan</title>
    <link>/</link>
    <description>Recent content on Isabella Duan</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 04 Dec 2022 17:08:10 +0000</lastBuildDate><atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>About me</title>
      <link>/posts/second/</link>
      <pubDate>Sun, 04 Dec 2022 17:08:10 +0000</pubDate>
      
      <guid>/posts/second/</guid>
      <description>Hey there! üëã I am Isabella, reading computational social science at the University of Chicago, currently on a gap year doing AI ethics &amp;amp; policy work at DeepMind.
I fall in love with complex questions in the intersection of AI and society. I am cautiously optimistic that AI will make the future awesome, but we must take the innitiative to make it happen. I would like to think like an ‚Äúinstitution designer,‚Äù constantly probing how we can create processes, norms, and organizations to make AI systems aligned with and accountable to people.</description>
    </item>
    
    <item>
      <title>Race to the Top: Rethink Benchmark-Making for Safe AI Development</title>
      <link>/posts/first/</link>
      <pubDate>Sat, 03 Dec 2022 17:08:10 +0000</pubDate>
      
      <guid>/posts/first/</guid>
      <description>Executive Summary Benchmarks support the empirical, quantitative evaluation of progress in AI research. Although benchmarks are ubiquitous in most subfields of machine learning, they are still rare in the subfield of AI safety.
In this post, I argue that creating benchmarks should be a high priority for AI safety. While this idea is not new, I think it may still be underrated. Among other benefits, benchmarks would make it much easier to:</description>
    </item>
    
    
    
  </channel>
</rss>
